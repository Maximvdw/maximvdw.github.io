<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:base="en-UK">
  <title>Maximvdw&#39;s Blog</title>
  <subtitle>An open-source hybrid positioning system framework.</subtitle>
  <link href="https://maximvdw.be/feed.xml" rel="self"/>
  <link href="https://maximvdw.be"/>
  <updated>2025-01-14T00:00:00Z</updated>
  <id>https://maximvdw.be</id>
  <author>
    <name>Maxim Van de Wynckel</name>
    <email>maxim.van.de.wynckel@vub.be</email>
  </author>
  
  <entry>
    <title>The privacy of location data is an open problem</title>
    <link href="https://maximvdw.be/posts/2025/01/14/"/>
    <updated>2025-01-14T00:00:00Z</updated>
    <id>https://maximvdw.be/posts/2025/01/14/</id>
    <content type="html">&lt;p&gt;A few years ago, a &lt;a href=&quot;https://9to5mac.com/2022/02/28/apps-sell-your-location-data/&quot;&gt;news article&lt;/a&gt; was published concerning the sale of location data by apps, despite the privacy policies of app stores. The first question you might ask yourself as a user is &lt;em&gt;why&lt;/em&gt; services want to buy or collect your location data. The answer is simple: money. Companies can use your location data to target you with ads or even sell it to other companies. This is not only a privacy issue but also a security issue.&lt;/p&gt;
&lt;p&gt;Imagine this, you use your favorite fitness application to track your running sessions. The app collects your location data to show you your running route. Suddenly, you start seeing advertisements for shops on your route. Other applications such as Amazon start to show you ads for running shoes. This is not a coincidence.&lt;/p&gt;
&lt;p&gt;These types of issues are not new, but they are definitely not the most severe. Millions of users use Google Timeline which keeps track of your location over time. For you as a user, it offers the ability to see how busy a location is, when you last visited a certain point of interest, or track your walks through a city you visited. On the 14th of March, 2018 - &lt;a href=&quot;https://www.nytimes.com/interactive/2019/04/13/us/google-location-tracking-police.html&quot;&gt;a murder was committed without any witnesses&lt;/a&gt; in Phoenix, US. A short time later, police apprehended the suspect by making use of location data that Google provided.&lt;/p&gt;
&lt;p&gt;In Europe, we have better protection against the misuse of location data and companies are required to provide clear privacy policies on how they use your data. It is one of the reasons why Google &lt;a href=&quot;https://www.oitc.ca/alerts/google-maps-timeline-data-to-be-stored-locally-on-your-device-for-privacy/&quot;&gt;started to move location data locally to a smartphone&lt;/a&gt;. While this helps to ensure that location data cannot be (forcefully) requested or sold by third parties, it brings a wide range of other problems with it pertaining to the accessibility of the data. Google already has a large monopoly on location data and location insights through their mobile applications such as Google Maps or Waze. They provide a privacy policy that states &lt;a href=&quot;https://policies.google.com/privacy?hl=en-US#europeanrequirements&quot;&gt;how they use location data&lt;/a&gt; with one of the prominent statements being that they do not sell data. Despite this, they still collect a wide range of data that can be used to track you or your friends, family members, or colleagues.&lt;/p&gt;
&lt;figure class=&quot;article&quot;&gt;
&lt;img src=&quot;https://i.mvdw-software.com/chrome_lMtDXl6dR9.png&quot; alt=&quot;Google&#39;s privacy policy snippet highlighting their data collection practices&quot; /&gt;
&lt;figcaption&gt;Google&#39;s privacy policy snippet highlighting their data collection practices&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Data includes expected information such as the IP address, GPS location data, and regular activity on Google Services. However, it goes a lot further with the collection of sensor data from your device, such as the accelerometer. Additionally, external information is collected, such as the Wi-Fi access points around you, Bluetooth-enabled devices, and cell towers. Internally, Google could potentially use this information to not only track yourself but also your friends, family members, or colleagues. For example, if your coworker uses a Bluetooth headset and you are in the same room, Google could potentially determine when your colleague is in the same room, even if they do not use Google&#39;s services.&lt;/p&gt;
&lt;p&gt;Even unintentionally, location data can find its way to unwanted parties. In December of 2025, it became known that the &lt;a href=&quot;https://www.theverge.com/2024/12/30/24332181/volkswagen-data-leak-exposed-location-evs&quot;&gt;location data, including personal information of 800,000 Volkswagens&lt;/a&gt; was available through an insecure endpoint.&lt;/p&gt;
&lt;figure class=&quot;article&quot;&gt;
&lt;img src=&quot;https://maximvdw.be/posts/2025/01/volkswagen.webp&quot; alt=&quot;Volkswagen visualization (source: Michael Kreil and Flüpke)&quot; /&gt;
&lt;figcaption&gt;Visualization of Volkswagen data leak (source: Michael Kreil and Flüpke)&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;I am investigating possible solutions to this problem. We are developing a system that allows users to control their location data. This system will allow users to decide who can access their location data and for what purpose. This way, users can still use their favorite fitness application without having to worry about their location data being sold to third parties. To further position this research, we are conducting a survey to understand how users feel about the current state of location data privacy and transparency.&lt;/p&gt;
&lt;p&gt;If you have &lt;strong&gt;15 minutes&lt;/strong&gt; you can really help to make a difference in this investigation. The survey is available &lt;a href=&quot;https://vub.fra1.qualtrics.com/jfe/form/SV_0TUPKzDuCnrje9U&quot;&gt;on Qualtrics&lt;/a&gt; till mid-February. Your answers will be anonymized and used to further develop the system.
A few years ago, a &lt;a href=&quot;https://9to5mac.com/2022/02/28/apps-sell-your-location-data/&quot;&gt;news article&lt;/a&gt; was published concerning the sale of location data by apps, despite privacy policies of app stores. The first question you might ask yourself as a user is &lt;em&gt;why&lt;/em&gt; services want to buy or collect your location data. The answer is simple: money. Companies can use your location data to target you with ads, or even sell it to other companies. This is not only a privacy issue, but also a security issue.&lt;/p&gt;
&lt;p&gt;Imagine this, you use your favorite fitness application to track your running sessions. The app collects your location data to show you your running route. Suddenly, you start seeing advertisements for shops on your route. Other applications such as Amazon start to show you ads for running shoes. This is not a coincidence.&lt;/p&gt;
&lt;p&gt;These types of issues are not new, but they are definitely not the most severe. Millions of users use Google Timeline which keeps tracks of your location over time. For you as a user it offers the ability to see how busy a location is, when you last visited a certain point of interest or track your walks through a city you visited. On the 14th of March, 2018 - &lt;a href=&quot;https://www.nytimes.com/interactive/2019/04/13/us/google-location-tracking-police.html&quot;&gt;a murder was committed without any witnesses&lt;/a&gt; in Phoenix, US. A short time later, police aprehanded the suspect by making use of location data that Google provided.&lt;/p&gt;
&lt;p&gt;In Europe, we have better protection against the misuse of location data and companies are required to provide clear privacy policies on how they use your data. It is one of the reasons why Google &lt;a href=&quot;https://www.oitc.ca/alerts/google-maps-timeline-data-to-be-stored-locally-on-your-device-for-privacy/&quot;&gt;started to move location data locally to a smartphone&lt;/a&gt;. While this helps to ensure that location data can not be (forcefully) requested or sold by third parties, it brings a wide range of other problems with it pertaining to the accessibility of the data. Google already has a large monopoly on location data and location insights through their mobile applications such as Google Maps or Waze. They provide a privacy policy that states &lt;a href=&quot;https://policies.google.com/privacy?hl=en-US#europeanrequirements&quot;&gt;how they use location data&lt;/a&gt; with one of the prominment statements being that they do not sell data. Despite this, they still collect a wide range of data that can be used to track you or your friends, family members or colleagues.&lt;/p&gt;
&lt;figure class=&quot;article&quot;&gt;
&lt;img src=&quot;https://i.mvdw-software.com/chrome_lMtDXl6dR9.png&quot; alt=&quot;VGoogle&#39;s privacy policy snippet highlighting their data collection practices&quot; /&gt;
&lt;figcaption&gt;Google&#39;s privacy policy snippet highlighting their data collection practices&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Data includes expected information such as the IP address, GPS location data and regular activity on Google Services. However, it goes a lot further with the collection of sensor data from your device, such as the accelerometer. Additionaly, external information is collected, such as the Wi-Fi access points around you, Bluetooth-enabled devices, and cell towers. Internally, Google could potentially use this information to not only track yourself, but also your friends, family members or colleagues. For example, if your coworker uses a Bluetooth headset and you are in the same room, Google could potentially determine when your colleague is in the same room, even if they do not use Google&#39;s services.&lt;/p&gt;
&lt;p&gt;Even unintentionally, location data can find its way to unwanted parties. In December of 2025 it became known that the &lt;a href=&quot;https://www.theverge.com/2024/12/30/24332181/volkswagen-data-leak-exposed-location-evs&quot;&gt;location data, including personal information of 800.000 Volkswagens&lt;/a&gt; was available through an insecure endpoint.&lt;/p&gt;
&lt;figure class=&quot;article&quot;&gt;
&lt;img src=&quot;https://maximvdw.be/posts/2025/01/volkswagen.webp&quot; alt=&quot;Volkswagen visualisation (source: Michael Kreil and Flüpke)&quot; /&gt;
&lt;figcaption&gt;Visualization of Volkswagen data leak (source: Michael Kreil and Flüpke)&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;I am investigating possible solutions to this problem. We are developing a system that allows users to control their location data. This system will allow users to decide who can access their location data and for what purpose. This way, users can still use their favorite fitness application without having to worry about their location data being sold to third parties. To further position this research, we are conducting a survey to understand how users feel about the current state of location data privacy and transparancy.&lt;/p&gt;
&lt;p&gt;If you have &lt;strong&gt;15 minutes&lt;/strong&gt; you can really help to make a difference in this investigation. The survey is available &lt;a href=&quot;https://vub.fra1.qualtrics.com/jfe/form/SV_0TUPKzDuCnrje9U&quot;&gt;on Qualtrics&lt;/a&gt; till mid-February. Your answers will be anonymised and used to further develop the system.&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>FOSDEM 2025: Discovering indoor environments and positioning systems</title>
    <link href="https://maximvdw.be/posts/2024/12/18/"/>
    <updated>2024-12-18T00:00:00Z</updated>
    <id>https://maximvdw.be/posts/2024/12/18/</id>
    <content type="html">&lt;p&gt;&lt;strong&gt;Have you ever gotten lost in a building and wished they had some sort of navigation system or at least a floor plan? I have, unfortunately, and it was only later that I realised that not only they had a floor plan online - but they had a navigation app for that building. The reality is that a user who is not familiar with a building will not find such an app until it&#39;s too late. Indoor environments sometimes have public floorplans available via some service. Similarly, more and more indoor positioning systems are being deployed in buildings to provide navigation services or asset tracking. However, as a person visiting a building, you are often not aware that these services exist or where to find them. Even if some global registry exists to discover this data, it is often proprietary, discouraging developers from interfacing with such systems. I want to bring a shift into the landscape of indoor positioning systems and services and solve this! In this presentation, I will talk about discovering indoor environments and positioning systems through local and global discovery methods, linked data and personal data vaults. How nice would it be, that instead of downloading the FOSDEM app, you simply use Google Maps or any open-source navigation application to find the location of this talk?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Got lost in a building and wished for a navigation system? I have – and it was only later that I discovered one existed! The reality is, that indoor navigation tools often go unnoticed by visitors, even if they’re available.&lt;/p&gt;
&lt;p&gt;I&#39;ll be speaking at FOSDEM (Geospatial Devroom - room AW1.120) on February 1st at 11:00 about how to make indoor positioning systems and environments more discoverable and accessible, using local/global discovery methods, linked data, and our SemBeacon specification.
&lt;a href=&quot;https://fosdem.org/2025/schedule/event/fosdem-2025-4526-discovering-indoor-environments-and-positioning-systems/&quot;&gt;https://fosdem.org/2025/schedule/event/fosdem-2025-4526-discovering-indoor-environments-and-positioning-systems/&lt;/a&gt;&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>Putting an Artificial brain in my Sumo Robot</title>
    <link href="https://maximvdw.be/posts/2019/06/07/"/>
    <updated>2019-06-07T00:00:00Z</updated>
    <id>https://maximvdw.be/posts/2019/06/07/</id>
    <content type="html">&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:1100/format:webp/1*pbM_M0aL6KMKypb6UrvERA.jpeg&quot; alt=&quot;captionless image&quot; /&gt;&lt;/p&gt;
&lt;p&gt;About a year ago, I created the first prototype for my sumo robot. For those who are not familiar with the game: It consists of a circular playing field with a contrast line at the edge.&lt;/p&gt;
&lt;p&gt;Autonomous robots have to find their opponents by using sensors and try to win the game by being the last one standing. This can be achieved by pushing the other robot(s) out of the arena.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:1142/format:webp/1*2K3r7ymva8yJDwkvtU1LLg.png&quot; alt=&quot;Example of a sumo robot pushing an opponent out of the arena Retrieved from http://www.ourgemcodes.com/japanese-pepe-sumo-robotics-sport-incredible-speeds/&quot; /&gt;&lt;/p&gt;
&lt;p&gt;The game is really simple, but the challenge is to create a robot that is fast, strong and has a good algorithm to find other opponents without falling off the edge.&lt;/p&gt;
&lt;h1 id=&quot;the-idea&quot; tabindex=&quot;-1&quot;&gt;The idea&lt;/h1&gt;
&lt;p&gt;My first reaction after creating the robot was to program it using a simple decision tree. It basically consisted of different actions for different sensor values.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;For example:&lt;/strong&gt;
“If both front line sensors are on make a 180 degree turn”
“If no line sensors are active and there is an object in front go forward”&lt;/p&gt;
&lt;p&gt;This is a good first program to test the robot, but it is very predictive. Programmers competing in such events can easily change their algorithm based on opponents with specific weaknesses.&lt;/p&gt;
&lt;p&gt;That is why I wanted to put an artificial brain inside my robot so I can somehow train it to become stronger and learn from mistakes or problems.&lt;/p&gt;
&lt;p&gt;And lets just be honest… it’s cool right?&lt;/p&gt;
&lt;h1 id=&quot;the-problem&quot; tabindex=&quot;-1&quot;&gt;The problem&lt;/h1&gt;
&lt;p&gt;If I would ask you to learn Chinese, how would you rate yourself in succeeding to do so? Would you ask someone who speaks the language to grade you? Or would you compare it to some YouTube videos? The same problem exists with training the brain for my sumo robot…&lt;/p&gt;
&lt;p&gt;How can you give a “score” on the success of the robot. I quickly came to the conclusion that it is almost impossible/slow to do this in real life, so I decided to create a simulation.&lt;/p&gt;
&lt;p&gt;The simulation is basically a game representing the sumo arena with my robot on scale. For the first couple of tests I decided to create the engine myself instead of using an existing game engine. This allowed me to skip the learning part for those engines while I was learning more about the AI aspect of the project. However when I started to create a simulation where I actually had to push objects I started to waste a lot of time on the physics involved with this so I used JBox2D as the physics engine.&lt;/p&gt;
&lt;h2 id=&quot;recreating-my-robot-in-the-simulation&quot; tabindex=&quot;-1&quot;&gt;Recreating my robot in the simulation&lt;/h2&gt;
&lt;p&gt;Because my robot would not have a learning brain and only use the best trained brain in the simulation I had to recreate the real life situation as closely as possible.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QCksUJhJpZJyUjojUqlSAg.png&quot; alt=&quot;Inventor design of my robot’s frame&quot; /&gt;&lt;/p&gt;
&lt;p&gt;This process involved getting the exact sensor locations and specifications, such as field of view of my distance sensors.&lt;/p&gt;
&lt;p&gt;My robot has 8 sensors in total. The front has two IR sensors that have a small FOV but a small range. I originally added them for last second adjustments in aligning the opponent on the front scoop. Normally the front is completely covered with a low reflecting black scoop. However it is temporarily removed for development (I really need to add an USB port on the top for the next revision).&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zDlJz3T2fmwMytDPCtZmNQ.png&quot; alt=&quot;captionless image&quot; /&gt;&lt;/p&gt;
&lt;p&gt;On the side there are two long range sonar sensors. They have a larger FOV resulting in not being able to detect small objects that are far away. However it can detect objects that are about 3 meters away.&lt;/p&gt;
&lt;p&gt;Since the rules of a local competition here in Belgium stated that the audience has to be 2 meters away from the field I’ve set the threshold of the sonar sensors to be 1.5m to prevent it from seeing the audience as opponents.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g_jpRHARJ_L_qgoTVADkjg.png&quot; alt=&quot;captionless image&quot; /&gt;&lt;/p&gt;
&lt;p&gt;On the bottom are 4 line sensors. They are calibrated at the start of the game to return 1 when a line is detected.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1hzmrA3FLm9MGZhy6FoJaQ.png&quot; alt=&quot;captionless image&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;recreating-situations-in-the-game&quot; tabindex=&quot;-1&quot;&gt;Recreating situations in the game&lt;/h2&gt;
&lt;p&gt;Creating a game with robots that can move around with sensors is great, but this is not a real life scenario. In order to improve the brain we need to feed it as much scenario’s as possible.&lt;/p&gt;
&lt;p&gt;Robots that attack, objects that randomly spawn, invalid sensor values or incorrect rotations due to friction. Especially those last problems are important. I wanted my brain to be able to work in less than perfect conditions. Soon after creating my first prototype I noticed that my IR sensors were interfering with each other. It would be interesting to see how the robot adapts to those “imperfections”.&lt;/p&gt;
&lt;p&gt;As long as our simulation can be as close to the real world as possible we can train it on fast hardware to make it apply to real life scenario’s.&lt;/p&gt;
&lt;h1 id=&quot;the-brain&quot; tabindex=&quot;-1&quot;&gt;The brain&lt;/h1&gt;
&lt;p&gt;The brain is what receives the inputs from various things the robot knows such as sensor values and outputs as actions that hopefully have a positive impact on the behavior of the robot.&lt;/p&gt;
&lt;h2 id=&quot;neural-network&quot; tabindex=&quot;-1&quot;&gt;Neural network&lt;/h2&gt;
&lt;p&gt;A neural network consists of &lt;strong&gt;neurons&lt;/strong&gt; that can store a value**.** Between neurons are pathways called &lt;strong&gt;synapses.&lt;/strong&gt; These synapses have a &lt;strong&gt;weight&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UZVUmjVEdnt46LCleZH3kQ.png&quot; alt=&quot;Example of a neural network with 10 inputs and 4 outputs&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Some of these neurons are the actual input we feed to the network and others are the output. When we compute the network it reads the value from the input neurons and computes each neuron until the output neurons are filled.&lt;/p&gt;
&lt;p&gt;The computation for each neuron is done by taking the sigmoid of the summation of the multiplied weights of each synapse with the input neuron(s). The sigmoid is a function that allows for a more smoother transition between states (for example 0 and 1). To make a quick metaphore: You can do something ‘good’ or ‘bad’. But if you have more states (very good, good, normal, …) you have the ability to adapt in making it better.&lt;/p&gt;
&lt;h2 id=&quot;genetic-algorithm&quot; tabindex=&quot;-1&quot;&gt;Genetic Algorithm&lt;/h2&gt;
&lt;p&gt;Genetic Algorithms (GA for short) are actually really simple to understand since they resemble the real world so closely. You start with a specific amount of &lt;strong&gt;species&lt;/strong&gt; in a generation.&lt;/p&gt;
&lt;p&gt;A species consists of multiple &lt;strong&gt;genomes&lt;/strong&gt; that are all similar to each other, be it with their own differences.&lt;/p&gt;
&lt;p&gt;When the GA starts it will test all those genomes in all the species. The first time the genomes are completely randomly generated. However some genomes perform better than others.&lt;/p&gt;
&lt;p&gt;After the testing of the species they are rated on their average success. The worst species are removed and the best are bred to create better offspring’s by checking for similarities between genomes and mutating the children.&lt;/p&gt;
&lt;p&gt;This process continues endlessly until there keeps getting better genomes.&lt;/p&gt;
&lt;h2 id=&quot;neuroevolution-of-augmenting-topologies&quot; tabindex=&quot;-1&quot;&gt;&lt;strong&gt;Neuroevolution of Augmenting Topologies&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;I used the genetic algorithm NEAT (Neuroevolution of Augmenting Topologies) for this project. It uses the idea of a genetic algorithm but with neural networks as the “brains” and thing that needs to evolve.&lt;/p&gt;
&lt;p&gt;The neural network layout remains the same. However the synapses are now the genes that can lead to better offspring’s.&lt;/p&gt;
&lt;h2 id=&quot;categorizing-species&quot; tabindex=&quot;-1&quot;&gt;Categorizing species&lt;/h2&gt;
&lt;p&gt;Species are genomes with similar &lt;strong&gt;genes&lt;/strong&gt;. This comparison is made by comparing the difference in weight and amount of links between two genomes.&lt;/p&gt;
&lt;p&gt;This categorization is important. If the threshold that indicates the similarity is too high there will be less species. Since species breed from their own genomes this could cause a stall in evolution.&lt;/p&gt;
&lt;h2 id=&quot;crossover&quot; tabindex=&quot;-1&quot;&gt;Crossover&lt;/h2&gt;
&lt;p&gt;After a generation finished it’s run it is time to create children from successful species in order to make better variations.&lt;/p&gt;
&lt;p&gt;This process is called crossover between species. There is a configurable change that it happens with another species before a mutation occurs. It is done by comparing each gene from both genomes with it’s &lt;strong&gt;innovation&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Innovation is given to genes when a genome mutates a new synapse. It indicates how new a synapse is compared to others. If a new synapse has a positive influence on a genome’s score it is most likely the cause of the most newer synapses instead of those basic ones generated in the beginning.&lt;/p&gt;
&lt;h2 id=&quot;mutation&quot; tabindex=&quot;-1&quot;&gt;Mutation&lt;/h2&gt;
&lt;p&gt;Mutation happens randomly. However the chance this happens is configurable. There are different kinds of mutations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Link&lt;/strong&gt; mutation: This mutation creates a new link between two neurons. The source neuron can’t be an output neuron and the distance neuron can’t be an input neuron.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bias&lt;/strong&gt; mutation: This mutation is similar to a link mutation. However the difference is that it uses a bias neuron. A bias neuron is a neuron that is not affected by inputs. It basically allows you to shift the output value to create a more appropriate output.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Connection&lt;/strong&gt; mutation: An existing random synapse is taken and a random amount of steps are added or subtracted from it. Sometimes the synapse can completely mutate to a different value.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Node&lt;/strong&gt; mutation: Another node is added to the network by selecting a random enabled synapse — duplicating it and placing the new neuron in between.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Disable&lt;/strong&gt; mutation: Selects a random synapse from enabled synapses and disables it. A disabled synapse will not be computed.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Enable&lt;/strong&gt; mutation: Selects a random synapse from disabled synapses and enables it again.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Configuration these mutations is important in both the speed of the training and simplicity of the brain. Node and link mutations for example can cause big effects on the mutated species.&lt;/p&gt;
&lt;p&gt;You have to remember that big changes can lead to species devolving causing more and more mutations to occur.&lt;/p&gt;
&lt;p&gt;Multiple mutations can happen on one species however the probability of other mutations happening lowers depending on if other mutations happened.&lt;/p&gt;
&lt;h1 id=&quot;the-simulation&quot; tabindex=&quot;-1&quot;&gt;The simulation&lt;/h1&gt;
&lt;p&gt;I created 5 basic test throughout the programming of the simulation. the simulation is definitely not completed. But the idea is that by using this you can create more and more scenario’s to keep the brain learning.&lt;/p&gt;
&lt;h2 id=&quot;information-is-important&quot; tabindex=&quot;-1&quot;&gt;Information is important&lt;/h2&gt;
&lt;p&gt;We do not want to compute the network a single time. The idea is that every “frame” or “tick” the neural network computes the inputs and decides what to do that tick.&lt;/p&gt;
&lt;p&gt;That means our neural network has no knowledge of previous events. To counteract this you have to provide the brain with as much information you as a programmer would have as well such as the perception of time, … .&lt;/p&gt;
&lt;h2 id=&quot;test-1%3A-do-not-die&quot; tabindex=&quot;-1&quot;&gt;Test 1: Do not die&lt;/h2&gt;
&lt;p&gt;I started with a very basic formula. It’s success was defined by the distance it traveled forward.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MAejxvzvXeKP0pO11bBvBg.png&quot; alt=&quot;The robots stay close to the sides&quot; /&gt;&lt;/p&gt;
&lt;p&gt;This looked great in the beginning, but after many generations you have some robots following the lines or trailing them.&lt;/p&gt;
&lt;p&gt;Robots die if all their line sensors are outside the field so as long as one sensor was in the boundary it would continue to try and move.&lt;/p&gt;
&lt;h2 id=&quot;test-2%3A-do-not-die-and-do-not-stay-on-lines&quot; tabindex=&quot;-1&quot;&gt;Test 2: Do not die and do not stay on lines&lt;/h2&gt;
&lt;p&gt;My next attempt had a few additional changes. First and foremost they now die when 2 line sensors are outside the field. Next changes include a drop in score every tick the line sensors are active.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VRGdOqlSjnUUHaSdQmCTIg.gif&quot; alt=&quot;captionless image&quot; /&gt;&lt;/p&gt;
&lt;p&gt;It was very interesting to see that the robots made longer straight movements instead of staying near the lines. Note that the simulation is sped up.&lt;/p&gt;
&lt;p&gt;I think the best change was to let them die when two sensors were out of the boundaries, since this would give inaccurate results causing them to follow the line instead of avoiding it.&lt;/p&gt;
&lt;p&gt;One thing I do noticed with this attempt was that the species only used their front two sensors since they can not go backwards. This is something I will have to test for future attempts.&lt;/p&gt;
&lt;h2 id=&quot;test-3%3A-touching-objects&quot; tabindex=&quot;-1&quot;&gt;Test 3: Touching objects&lt;/h2&gt;
&lt;p&gt;The next day I kept adding more features to the program. The robots were able to move backwards (but it was discouraged with lesser points — and they actually never used it) and I added objects and distance sensors to the game with the goal to touch them.&lt;/p&gt;
&lt;p&gt;Stationary objects are randomly spawned. The robots get a lot of points for touching them. This caused the species to evolve to read those distance sensors in finding the objects.&lt;/p&gt;
&lt;p&gt;In this attempt distance sensors were boolean, they only knew if an object was in its range.&lt;/p&gt;
&lt;p&gt;Defining the fitness function for this was actually very hard. As I had to find a function that both encouraged the pushing and movement. The problem I was facing at first was that the robots would just stand in front of objects. What I was fearing the most was to make the success function to “precise”.&lt;/p&gt;
&lt;p&gt;I ended up trying different approaches ranging from giving points for the collision to giving points when an objects is in sight. Because giving points when an object is in sight would just make it keep the object in FOV I decided to give points when the robot “pushes” a robot. This I achieved by giving points when the robot goes forward when the IR sensors see an object.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g2ppWzPy-AcFOjZMR48Hag.gif&quot; alt=&quot;Robots trail the edge to find the objects that spawn near the border&quot; /&gt;&lt;/p&gt;
&lt;p&gt;The first test had a mathematical issue in spawning the objects, causing them to be always near the border. This caused species to evolve in trailing the edge. This was actually smarter than trying to find the object using the distance sensors since no mater what they did.. they would always find an object.&lt;/p&gt;
&lt;p&gt;After fixing the issue with the wrong spawning it started to look a bit better. However I faced an issue I had not foreseen. I created a static “speed” and turning rate per tick. But this meant that there were issues in the dead zone (the zone where no sensors see anything). The following example shows that it goes forward after turning to try and keep the object within the sensor.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6dIQFlHMqbt4lIkUpIKrhg.gif&quot; alt=&quot;captionless image&quot; /&gt;&lt;/p&gt;
&lt;p&gt;After seeing this issue I decided to alter my simulation to have a variable turning rate and to make the distance sensors actually return the distance of the object rather than a boolean value. Meaning the output is multiplied to determine the rate it turns. However this requires to add momentum to the simulation since it needs to remember at the next tick that it is still performing a turn.&lt;/p&gt;
&lt;h2 id=&quot;test-4%3A-touching-objects-as-fast-as-possible&quot; tabindex=&quot;-1&quot;&gt;Test 4: Touching objects as fast as possible&lt;/h2&gt;
&lt;p&gt;Something I noticed from the previous test was that the species would “patrol” when they did not find an object. Eventually they would hit a line and move their position a bit. They gain points by moving and catching objects, but they have ages to do so. In a real life scenario the robots have to push out the opponents as fast as possible to prevent them from pushing you out.&lt;/p&gt;
&lt;p&gt;I’ve began to think of other inputs my Arduino might have, since I wanted to add momentum to the robot I decided to return the remaining momentum as an input instead of programming this myself.&lt;/p&gt;
&lt;p&gt;I also added another way to die. If a robot did not touch an object within 3000 ticks it would be dead. This eliminated most “lucky” robots.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZT0UYtYQmKAjl4qE2WNt9g.gif&quot; alt=&quot;Robots began to learn how far they had to rotate&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Now that rotation was no longer a constant they had the choice to learn how much they have to rotate when seeing different sensor values. You could easily see them progressing generation by generation.&lt;/p&gt;
&lt;p&gt;I learned that I had to spawn in the object after a certain amount of time instead of instantly. This made them learn to stay in the arena instead of being challenged with things they did not yet understand. You first need to walk before you can run.&lt;/p&gt;
&lt;p&gt;Other changes included things to give more points for pushing. When an object was touched with the front of the robot it would gain more points than if it would be hit from the sides.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IeL5R32UOVzpFv5bU_U3-w.gif&quot; alt=&quot;After many generations it was able to find a somewhat perfect 90 degree rotation&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;test-5%3A-pushing-objects-out&quot; tabindex=&quot;-1&quot;&gt;Test 5: Pushing objects out&lt;/h2&gt;
&lt;p&gt;For my final test I fixed some missing features in the simulation such as distance instead of boolean values for the distance sensors. The objects have physics and can be pushed. The goal is similar to the previous test, but instead of touching the robot has to push the object out of the arena. I’ve removed a lot of the unneeded fitness points. Those unneeded points were once needed when there was no other goal (no objects to push out, …). Now that more and more features are being added it will become more clear to the robot what it’s purpose is.&lt;/p&gt;
&lt;p&gt;While creating this test I rewritten the simulation to use JBox2D to allow for better physics when pushing objects around.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tf9XYHZeK-n7fGBa04WRjA.gif&quot; alt=&quot;captionless image&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Even before using the physics engine I had a problem with robots chasing their tail by keep rotating towards an object they were moving in the same rotation. I came to the conclusion this was normal. Let’s look at the animation below. Wait till he reaches the top to see what I mean …&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:698/format:webp/1*U5xXy3hqijjmz4hAW1WC2g.gif&quot; alt=&quot;captionless image&quot; /&gt;&lt;/p&gt;
&lt;p&gt;When did you know this wasn’t going to end? Was it something you’ve seen in the picture or was it just a matter of &lt;strong&gt;time&lt;/strong&gt; that made you came to the conclusion?&lt;/p&gt;
&lt;p&gt;Time is a valuable linear input we humans have. In order for the brain to be able to know if something isn’t going to end it needs to know how long it has been happening.&lt;/p&gt;
&lt;p&gt;That is why I added a very simple input that I can also achieve with the Arduino. I added the ticks after the last forward/backward movement. The brain can choose what it does with this input, it can be ignored or used in the benefit of the robot. In many ways it is rather similar as the rotation momentum I’ve added earlier — since the rotation momentum decreases every tick with a set constant, meaning it can be used as a reference of time. The only difference here is that the rotation momentum can be different based on the inputs it received during that time. Meaning that it is more of a “countdown” rather than a counter.&lt;/p&gt;
&lt;p&gt;With simulations like this it is better to use some sort of &lt;strong&gt;other measurement&lt;/strong&gt; rather than ticks. For example: Imagine if it would learn to go backwards when it has been rotating for X ticks because it is seeing an object on the left sensor. It learns that it has to go backwards for 10 ticks in order for the object to travel the distance between it’s front and left sensor. In reality however your robot may be slower or faster causing this “prediction” to be inaccurate. Instead it would be wiser to use something that can’t change such as the distance traveled — this will of course not be accurate as well due to friction and other constraints that prevent you from getting precise movements. But by using a variable unit you can have more accurate results.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K5Qe3VX7E2g-No_QI_A2dQ.gif&quot; alt=&quot;After about 10 hours of training&quot; /&gt;&lt;/p&gt;
&lt;p&gt;It took some time to let it learn how to use the new input, since it allowed for “timed” movements — it started to find ways to gain a lot of points without actually doing much. There were still points given for going forward, so what it did was switching between going forward and rotating creating a big circle without touching the lines and gaining points rapidly for just … well spinning.&lt;/p&gt;
&lt;p&gt;Eventually it seemed some mutation gave them the ability to move towards objects and that “bad habit” was devolved.&lt;/p&gt;
&lt;p&gt;One thing you have to know about neural networks is that they are &lt;strong&gt;good&lt;/strong&gt; &lt;strong&gt;in what they train for&lt;/strong&gt; — when something deviates from the training they can show unexpected behavior. Just because it knows how to push an object out doesn’t mean it can handle two objects at a time.&lt;/p&gt;
&lt;p&gt;The following training randomly added multiple objects requiring the brain to choose between one of them when two sensors in different directions were showing an object. Another slight change included some physics properties for the robot to be affected by obstacles weight allowing me to put two robots against each other after the training.&lt;/p&gt;
&lt;p&gt;With these kinds of experiments there never is a “final result”, but this is a generation I am happy about.&lt;/p&gt;
&lt;h1 id=&quot;copying-the-brain&quot; tabindex=&quot;-1&quot;&gt;Copying the brain&lt;/h1&gt;
&lt;p&gt;It sound like something from Star Trek, but copying a brain is actually straightforward as long as the environment you trained it in looks similar to the one you are copying it to. Imagine it like copying a brain from a human with two legs to a mouse, it’s inputs and outputs are incompatible. We want to copy the best brain that is trained to our small Arduino in the robot.&lt;/p&gt;
&lt;p&gt;As said before the brain consists of neurons connected by weights. In order to copy this we just need to save those connections and copy it to the Arduino. Next we need to add the logic to “compute” the network. The robot won’t be able to train itself unfortunately but we can continue creating more features and situations in the game to let it learn.&lt;/p&gt;
&lt;h2 id=&quot;saving-the-trained-brain&quot; tabindex=&quot;-1&quot;&gt;Saving the trained brain&lt;/h2&gt;
&lt;p&gt;The first step was to output the brain so it could be copied to the Arduino. My first solution was to have to saved in a way it could be loaded at runtime by the Arduino. The problem is that it only has 2KB RAM and 32KB flash for programming code, meaning the RAM is way too low for the network to be stored in memory seeing it would easily exceed 10KB.&lt;/p&gt;
&lt;p&gt;Our brain doesn’t need to be in memory all the time. We just need to store it somewhere and compute it one neuron at the time while we store the output for later.&lt;/p&gt;
&lt;p&gt;The programming memory (flash) is big enough for our brain but can’t contain objects. There is a library called pgmspace that allows you to put constant variables into the programming memory so they can be read. But the construction of new objects using this is not possible.&lt;/p&gt;
&lt;p&gt;The internal EEPROM is only 1KB so that is not a possibility either. We could add an external module and create the neurons in our setup one by one and put them in the external EEPROM since the code for the creation of these neurons is in the flash. But I did not have such module so this was out of the question (for this robot revision anyway).&lt;/p&gt;
&lt;p&gt;I decide to go for the ugly approach and simply let my simulation generate a large amount of programming lines storing the neurons in local variables and using the weights in the calculation.&lt;/p&gt;
&lt;h2 id=&quot;uploading-the-brain-to-the-robot&quot; tabindex=&quot;-1&quot;&gt;Uploading the brain to the robot&lt;/h2&gt;
&lt;p&gt;After creating the basics of the sumo robot such as the countdown timer and the outputs it was time to just “copy paste” the generated code in-between the loop. The code looked ugly as hell but unfortunately there was no way to make it object oriented due to the low amount of SRAM available.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WVoCv3dblwfmtSfCXdi3aQ.png&quot; alt=&quot;The generated code uploaded to the arduino&quot; /&gt;&lt;/p&gt;
&lt;p&gt;I programmed the brain to have specific specifications for rotation per tick and movement per tick. To make the system work exactly as the simulation the outputs for the motors will be send but there won’t be a delay to wait until the rotation or movement is completed. The program will wait for the next tick and compute the network again to overwrite or keep the current action.&lt;/p&gt;
&lt;p&gt;Neurons can contain values from a previous evaluation of the network. Meaning the brain trained with this in mind. This means we have to keep the neuron variables global so they are not reset to 0 after evaluation.&lt;/p&gt;
&lt;h2 id=&quot;testing-the-robot&quot; tabindex=&quot;-1&quot;&gt;Testing the robot&lt;/h2&gt;
&lt;p&gt;The first tests were ,… well lets say I was spending so much time on it that I actually stopped it for a few months. The problem was mostly due to the slow Arduino and many decisions per second. Instead of smooth movements it was actually just doing a whole bunch of small little steps.&lt;/p&gt;
&lt;p&gt;On top of that — I had some design problems with my prototype what made it hard to debug the Arduino code and a lot of false positive front sensor detection due to the two same IR sensors pointing in the same direction.&lt;/p&gt;
&lt;p&gt;Eventually I’ve overcome these issues and managed to put the trained brain into the robot.&lt;/p&gt;
&lt;h1 id=&quot;what%E2%80%99s-next%3F&quot; tabindex=&quot;-1&quot;&gt;What’s next?&lt;/h1&gt;
&lt;p&gt;So we created a simulation with an easy to use engine, we trained a brain to push objects out of the game and we successfully uploaded it to our small Arduino that is in our hardware.&lt;/p&gt;
&lt;p&gt;This project is not finished for me. For starters I want to add more scenario’s to my simulation such as moving objects, invalid sensor values and more real life scenario’s.&lt;/p&gt;
&lt;p&gt;As more and more scenario’s will be added the training will become longer and longer — I may want to look at a server that distributes the training to idle peers (computers) I am using throughout the day. But that’s a topic for another time.&lt;/p&gt;
&lt;h1 id=&quot;conclusion-and-future-work&quot; tabindex=&quot;-1&quot;&gt;Conclusion and future work&lt;/h1&gt;
&lt;p&gt;It was a very interesting experience to do this project. Most of my time went in the creation of the simulation, but I had to stop myself from making my fitness function to precise. I always wanted to give or subtract points for actions that would be things that “I” would do instead of letting the algorithm finding it out in time.&lt;/p&gt;
&lt;p&gt;It became clear that choosing a correct fitness score is very important. Be too generous and evolution will find a way to exploit it in gaining points for basically nothing. Be too precise and your brain may evolve slowly or devolve over time.&lt;/p&gt;
&lt;p&gt;As for the “copy paste” to Arduino… well it worked, but it was a lot harder than I expected at first. I had to alter the momentum of the wheels for every neural network I tried because of the big difference in computation time.&lt;/p&gt;
&lt;p&gt;These are my tips for choosing a correct fitness score:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Learn to walk before you can run&lt;/strong&gt;: While our main goal is to push other opponents out it should not be the first step. I let the robot learn how to move and stay within the lines before actually spawning objects in. The saying “learn to walk before you run” also applies to this.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Don’t be too generous&lt;/strong&gt;: You may want to really force your brain to learn to do a specific action by giving a lot of points for pushing objects out. However — if the brain accidentally manages to push an object out without any logic behind it — it will become problematic for the future. Some other species may already start to learn to use sensor values to detect objects , but do not succeed yet. That is why you shouldn’t be too generous with points, especially in the beginning. You don’t want to evolve a species that survives on luck.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Don’t (always) subtract points for things you don’t want it to do:&lt;/strong&gt; When my robots started to follow the lines my first reaction was to subtract points. Some species evolved how I wanted it by crossing the circle every time, while others found a good rotation momentum that matches the circle so they could circle it without actually touching the line. Now think to yourself — is it problematic in real life that the robots touch the line? No, I just didn’t want them to do it because then they wouldn’t detect objects in the center. Instead you should give points on speed. Robots that push objects out faster will gain more points. Again don’t be too generous in the beginning.
But this does not mean you should never subtract points, for some scenario’s you may want to subtract points because in real life you would lose as well (like a timeout or something).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Do not kill them so fast:&lt;/strong&gt; It goes without saying that I killed all robots that crossed the line. However I also killed robots that didn’t manage to push out objects in time. Some species were lucky and pushed objects out randomly by zigzagging across the board — but others that were “smarter” but not evolved enough to accurately turn to an object were killed off. That is why I only started to kill robots after their 10th pushed out object. This is a bit similar to “learn to walk before you can run”.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Let them gain points based on inputs&lt;/strong&gt;: Imagine if the robot would only have line sensors and would randomly gain points when he pushed an object. It would most likely learn a way to move across the board and cover all possible corners so it would be sure to push an object. You would’ve programmed it with a collision detection in your simulation — but this is something the robot doesn’t have. Instead try to give points when you “think” he is pushing an object. For example when it’s going in the direction of a sensor.
I am not saying you should always do this, since you kinda force your own idea’s into the robot. But this isn’t always a bad thing.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Think how they might exploit your fitness score:&lt;/strong&gt; Think how the evolution might find a way to exploit your fitness score. For example: What do you think would happen if I’d give points for going towards an object? It sounds like a good plan but it isn’t. Evolution will find a way to exploit it by simply going backwards and forward every tick to gain an awful lot of points because going backwards doesn’t subtract them.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:1320/format:webp/1*Zvxhijq7zkDprGjD3oyvvA.jpeg&quot; alt=&quot;captionless image&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Do not over complicate things:&lt;/strong&gt; If you make your fitness score too “precise” and complicated you will not only force the robot into your own way of thinking but you will also make it complicated for yourself to see how they might exploit it.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Do not make the fitness score depend on other species:&lt;/strong&gt; When I first started the project I build in checks to see if there has been a “best” robot for a while — so if no change in “best” species happened it would end the generation and go to the next.
The problem with this: the more you begin to train the more similar species will become — causing the “best” robot to change often. This may seem like a good thing at first because you want the best of the best. But it may also work the other way around in giving you the worst species.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The question still remains if this is a viable solution to such a simple problem — or if this solution is just an over engineered fantasy of some student. I don’t think with the current simple tests, the time VS profit ratio is high but as more and more scenario’s and inputs are added it may become the best one. This will of course cause a bigger learning curve, but then again I don’t think it is a bad idea to “help” the brain in the right direction by providing more points in the fitness for better actions (such as going forward when the two sensors are active).&lt;/p&gt;
&lt;p&gt;I guess we all need a teacher. At the end it will be the apprentice who becomes the teacher.&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>How easy is it to hack my WiFi light bulb?</title>
    <link href="https://maximvdw.be/posts/2016/10/26/"/>
    <updated>2016-10-26T00:00:00Z</updated>
    <id>https://maximvdw.be/posts/2016/10/26/</id>
    <content type="html">&lt;h2 id=&quot;or-a-companies-whole-line-of-light-bulbs%3F&quot; tabindex=&quot;-1&quot;&gt;Or a companies whole line of light bulbs?&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:2000/format:webp/1*Ch6Jo0zRkE8aVedotNTMLw.png&quot; alt=&quot;captionless image&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Being a frugal student, I bought myself a 20$ light bulb and a 8$ RGB led strip controller so I could turn my lights on using my phone. After the IoT DDoS that took a part of the internet down on October 2016 I decided to check ‘how unsafe’ IoT devices like these light bulbs actually are. Articles describe the “theories” behind hacking “simple” IoT devices and the damage they could do — but how simple is it for a student like me to hack a light bulb (or maybe even all light bulbs of a company)&lt;/p&gt;
&lt;p&gt;The light bulb and RGB controller I am using are from a company called “MagicHue” and their app is called “Magic Home”.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The following is a proof of concept to make users and manufacturers aware of the dangers in creating/using IoT devices. Controlling lights has been done using personal devices. Information such as sessions, id’s and email’s are masked.&lt;/em&gt;&lt;/p&gt;
&lt;h1 id=&quot;step-1)-what-can-this-light-bulb%2Frgb-controller-actually-do%3F&quot; tabindex=&quot;-1&quot;&gt;Step 1) What can this light bulb/RGB controller actually do?&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KiEArK090hDHHqSw8G0S2w.jpeg&quot; alt=&quot;captionless image&quot; /&gt;&lt;/p&gt;
&lt;p&gt;To start, I disassembled my RGB led controller to see what is actually in there. It turns out to be an ESP8266 providing both the WiFi connection and code that makes the actual thing work.&lt;/p&gt;
&lt;p&gt;An ESP8266 is a cheap controller I actually used a lot in combination with an Arduino, so I did have some background information on it.&lt;/p&gt;
&lt;p&gt;The controller is simple and just does what it is programmed to do. I can understand that a smart device running a Linux variant would’ve been way easier to hack. But that doesn’t mean this thing can’t be controlled/hacked.&lt;/p&gt;
&lt;h1 id=&quot;step-2)-what-can-you-do-with-it%3F&quot; tabindex=&quot;-1&quot;&gt;Step 2) What can you do with it?&lt;/h1&gt;
&lt;p&gt;The next step a hacker would take is analyzing what actually can be done with the IoT device (in this case an RGB led controller).&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Turn the lights on and off&lt;/li&gt;
&lt;li&gt;Change the color and brightness&lt;/li&gt;
&lt;li&gt;Control using an iOS and Android app&lt;/li&gt;
&lt;li&gt;Bind a bulb to an account so it can be controlled from everywhere&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;step-3)-reverse-engineering-the-server-connection&quot; tabindex=&quot;-1&quot;&gt;Step 3) Reverse engineering the server connection&lt;/h1&gt;
&lt;p&gt;Now that we know that the light bulb controller itself doesn’t really have a lot of ‘easy to notice’ vulnerabilities, it is time to look for those vulnerabilities on the server the devices are connecting to.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mgZDvLAHfTOvMw2cwYA0rQ.png&quot; alt=&quot;captionless image&quot; /&gt;&lt;/p&gt;
&lt;p&gt;So like all remote IoT devices behind a firewall they connect to a server that gives your light bulb commands. When your phone makes an “authenticated” request to the server, it is able to use the server to relay actions to your light bulb.&lt;/p&gt;
&lt;p&gt;The question you have to ask yourself as a developer:&lt;/p&gt;
&lt;h2 id=&quot;%E2%80%9Chow-will-i-know-what-light-bulb-is-connected-to-a-specific-user%3F%E2%80%9D&quot; tabindex=&quot;-1&quot;&gt;“How will I know what light bulb is connected to a specific user?”&lt;/h2&gt;
&lt;p&gt;To do this the device needs to have “something unique” for that user/light bulb.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A good way would be to generate a random and secure key (or request a unique key from the server and store it somewhere on first start).&lt;/p&gt;
&lt;p&gt;Requesting an unique key from a server allows you to keep the method you are using the generate the unique key private + it helps to give you server side control on how many keys are actually being generated.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;But did the developers that created this ‘cheap’ hardware chose this approach? That is what we are going to find out …&lt;/p&gt;
&lt;h2 id=&quot;step-3.1)-analyzing-the-light-bulb-to-server-connection&quot; tabindex=&quot;-1&quot;&gt;Step 3.1) Analyzing the light bulb to server connection&lt;/h2&gt;
&lt;p&gt;This step is not always possible since some servers may communicate over SSL preventing you from reading the actual packets that the light bulb is sending to the server.&lt;/p&gt;
&lt;p&gt;I prepared the light bulb for remote connection. So It should be doing something with the server at that point:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It either &lt;strong&gt;polls&lt;/strong&gt; the server for changes (sending a request to the server every interval)&lt;/li&gt;
&lt;li&gt;It initializes a &lt;strong&gt;keep-alive connection&lt;/strong&gt; with the server (resource intensive for a server with many light bulbs)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I used Wireshark to sniff the traffic that was coming from my light bulb.&lt;/p&gt;
&lt;p&gt;The things I found didn’t really help me further, so I went on analyzing the application traffic. On other IoT device it is probably recommended to continue analyzing the IoT&amp;lt;-&amp;gt;server traffic.&lt;/p&gt;
&lt;h2 id=&quot;step-3.2)-analyzing-the-app-traffic&quot; tabindex=&quot;-1&quot;&gt;Step 3.2) Analyzing the app traffic&lt;/h2&gt;
&lt;p&gt;Checking the connection between the Android app and the server is easy. I used an app called “Packet Sniffer” that launches a MITM on a non-rooted Android phone and even allows you to see SSL requests in plain text.&lt;/p&gt;
&lt;p&gt;From earlier research I did to automatically turn on my lights when I enter my room I know that the connection between the App and light bulb is a normal socket TCP connection sending hex. The connection from the app to the server is done over plain HTTP and actions are send as hex in a HTTP JSON request.&lt;/p&gt;
&lt;p&gt;The protocol for the hex commands is for this proof of concept not important, it consists of hex commands followed by their arguments and a checksum — but for testing purposes we will just copy paste commands send from the app.&lt;/p&gt;
&lt;h2 id=&quot;checking-all-the-different-requests&quot; tabindex=&quot;-1&quot;&gt;Checking all the different requests&lt;/h2&gt;
&lt;p&gt;Most of the time I spend doing all sorts of different requests and saving them so I could analyse/redo them later.&lt;/p&gt;
&lt;p&gt;**Login:
**The login is fairly easy to sniff. It sends the UserId (email) with a hashed (md5) password.&lt;/p&gt;
&lt;p&gt;The result is an ASP.NET session cookie used for further actions.&lt;/p&gt;
&lt;p&gt;**Enabling remote on a device:
**This is basically a request that is made when you “Check” a checkbox asking to allow remote control.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:1002/format:webp/1*uXI0t2tSFVGeSyUyCBrcEw.png&quot; alt=&quot;HTTP request for binding a device&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Apart from the MAC address there is nothing unique to identify the device. The request does ask for device information, but it is not certain yet if this information will be validated to the connection that the light bulb makes to the server. I do not think that the time zone will be checked, since this is something that can be changed locally without it causing to break the remote function.&lt;/p&gt;
&lt;p&gt;**Disabling remote on a device:
**Same as enabling, but when unchecking the box.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:1002/format:webp/1*9vDh_SKs2jarVWcbvrFQEA.png&quot; alt=&quot;HTTP request for unbinding a device&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Disabling only requires a GET request with the MAC address.&lt;/p&gt;
&lt;p&gt;**Checking to what accounts a device is bound:
**Apparently the server supports binding a device to multiple accounts. This means we may be able to add someone else their light bulb if we know its MAC address (or brute force it?).&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:1002/format:webp/1*7RFlgr1H5nN-B0yBfH3Peg.png&quot; alt=&quot;HTTP request — getting users bound to device&quot; /&gt;&lt;/p&gt;
&lt;p&gt;The request is made after enabling remote on a device to display the following information inside the app:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:1002/format:webp/1*ZzFf4HMb7TdUpSJj6_xFLg.png&quot; alt=&quot;Original application: Accounts bound to device&quot; /&gt;&lt;/p&gt;
&lt;p&gt;**Turning on/off:
**Once remote is enabled you can turn it on/off using a request
(note: the hex command is different for on/off/color/…)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:1002/format:webp/1*M_vv4FeGHxB7xmZY5llXFw.png&quot; alt=&quot;HTTP request for an “action” to a light bulb&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;thinking-as-a-developer-%E2%80%94-what-would-you-do%3F&quot; tabindex=&quot;-1&quot;&gt;Thinking as a developer — What would you do?&lt;/h2&gt;
&lt;p&gt;We know how a simple “on/off” requests is done:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The user logs in with a request that takes:
a) The user email
b) The hashed password
c) Some version info
d) A check code (probably a checksum of the request) — UNKNOWN&lt;/li&gt;
&lt;li&gt;The response is a cookie used for future requests&lt;/li&gt;
&lt;li&gt;The user enables “remote” on the device sending a request containing:
a) **MAC Address (only identifier of a light bulb)
**b) Device information and model
c) Some version info
d) A check code (probably a checksum of the request) — UNKNOWN&lt;/li&gt;
&lt;li&gt;The request to turn on a light requires:
a) Some version information about the app (copy/paste)
b) **MAC Address (only identifier of a light bulb)
**c) The action in HEX (copy/paste)
d) A “check code” (probably a checksum of the request) — UNKNOWN
e) Timestamp (probably used in the check code)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You can clearly see that apart from the MAC address there is nothing ‘unique’ to identify a device. There is no unique key that you can’t guess… there is no password per device…. it’s just the MAC address.&lt;/p&gt;
&lt;p&gt;Think as a developer. What would you do on each request: What will you check, what will you do but above all… “What will you forget to check”.&lt;/p&gt;
&lt;h1 id=&quot;step-4)-what-protections-exists%3F&quot; tabindex=&quot;-1&quot;&gt;Step 4) What protections exists?&lt;/h1&gt;
&lt;p&gt;Now that we completely understand the working of the server connection we have a full overview of the existing protections and the gaping holes:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;We know that connecting to a bulb from inside the network doesn’t require any password or pin&lt;/li&gt;
&lt;li&gt;Logging in using the app is done over plain text with a hashed password&lt;/li&gt;
&lt;li&gt;Requests to login / performing an action have an unknown “CheckCode” argument&lt;/li&gt;
&lt;li&gt;Light bulbs are bound to an account by their MAC address only&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;step-5)-manually-creating-requests&quot; tabindex=&quot;-1&quot;&gt;Step 5) Manually creating requests&lt;/h1&gt;
&lt;p&gt;Once you know “What” requests are made, “How” they are made and “When” they are made — it is time to manually create them and change their purpose.&lt;/p&gt;
&lt;p&gt;The first thing I did was executing the EXACT HTTP requests I captured before (without changing anything).&lt;/p&gt;
&lt;h2 id=&quot;step-5.1)-turning-an-already-bound-device-on%2Foff&quot; tabindex=&quot;-1&quot;&gt;Step 5.1) Turning an already bound device on/off&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WbKTdw2maj-_sIa6ClqTzw.png&quot; alt=&quot;Executing a HTTP request to turn off the light (redoing previous captured)&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Result: It worked!&lt;/p&gt;
&lt;p&gt;This allows us to conclude a few things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The “Timestamp” can be used multiple times and does not need to be in the near future&lt;/li&gt;
&lt;li&gt;The “CheckCode” can be used multiple times&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;changing-the-mac-to-an-already-bound-device&quot; tabindex=&quot;-1&quot;&gt;Changing the MAC to an already bound device&lt;/h2&gt;
&lt;p&gt;The next thing I tried was simply changing the device to an already bound device. This worked as well allowing me to conclude that:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The “CheckCode” does not take the MAC address into account&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;changing-the-cookie-to-another-account&quot; tabindex=&quot;-1&quot;&gt;Changing the cookie to another account&lt;/h2&gt;
&lt;p&gt;Feeling hopeful I tried to change the cookie to that of another account I just created. The CheckCode, Timestamp and MAC stayed the same.&lt;/p&gt;
&lt;p&gt;The request failed with the following message:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bip9EFu5pHhSf9A9yRRZMw.png&quot; alt=&quot;Result of HTTP request with other account&quot; /&gt;&lt;/p&gt;
&lt;p&gt;The request failed, but we now know that the problem is either:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The checkcode depends on the user&lt;/li&gt;
&lt;li&gt;The device needs to be bound first&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;step-5.2)-binding-a-device-to-an-account&quot; tabindex=&quot;-1&quot;&gt;Step 5.2) Binding a device to an account&lt;/h2&gt;
&lt;p&gt;To test this, I first removed the device from my account. After that I just executed the same command again.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_UacLxTZWDkQ-mUsavkVnQ.png&quot; alt=&quot;HTTP request to bind a device&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Result: The request worked, and when I looked in the app the device was in there!&lt;/p&gt;
&lt;h2 id=&quot;changing-the-mac-to-another-device&quot; tabindex=&quot;-1&quot;&gt;Changing the MAC to another device&lt;/h2&gt;
&lt;p&gt;This is perhaps the most important test in this article. If this works — it means we can bind to any device by just knowing or guessing the MAC address.&lt;/p&gt;
&lt;p&gt;I executed the command from another WAN address than the IP address of the device — so I was certain that wasn’t used as a check.&lt;/p&gt;
&lt;p&gt;Result: It worked!&lt;/p&gt;
&lt;p&gt;I managed to add a device bound to another account without changing the device specifications.&lt;/p&gt;
&lt;p&gt;In the application the new device showed it being bound to two accounts — the icon/information about the device was incorrect since I didn’t change it. This allows us to conclude:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The “CheckCode” does not take the MAC address into account&lt;/li&gt;
&lt;li&gt;The device can be added by only knowing the MAC address&lt;/li&gt;
&lt;li&gt;The device specifications/type does not matter when adding&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;changing-the-cookie-to-another-account-1&quot; tabindex=&quot;-1&quot;&gt;Changing the cookie to another account&lt;/h2&gt;
&lt;p&gt;This test was the same as 5.1, where I just change the cookie to another account that does not have the device bound to it.&lt;/p&gt;
&lt;p&gt;Result: It worked!&lt;/p&gt;
&lt;p&gt;This lets us conclude a few more things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The “CheckCode” does not take the user into account (we now know that this is the same case as in 5.1 , so that means we just need to bind a device first before performing actions on it)&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;step-5.3)-turning-an-unbound-device-on%2Foff&quot; tabindex=&quot;-1&quot;&gt;Step 5.3) Turning an unbound device on/off&lt;/h2&gt;
&lt;p&gt;What we know of step 5.1 and 5.2 is that we can perform an action from the moment we bind a device to an account.&lt;/p&gt;
&lt;p&gt;Result: It worked!&lt;/p&gt;
&lt;p&gt;After just binding the device I was able to perform the hex command on the newly bound device without any problem.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;At this point, we have managed to control any light bulb of that company by just knowing their MAC address.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;step-6)-automating-the-whole-thing&quot; tabindex=&quot;-1&quot;&gt;Step 6) Automating the whole thing&lt;/h1&gt;
&lt;p&gt;What we did from step 1–5 was research on how everything worked. We may now know how to control IoT lightbulbs of MagicHue by just knowing their MAC address — but what does this actually mean?&lt;/p&gt;
&lt;h2 id=&quot;brute-forcing-the-possible-mac-addresses&quot; tabindex=&quot;-1&quot;&gt;Brute forcing the possible MAC addresses&lt;/h2&gt;
&lt;p&gt;A first thing a hacker could do is just brute forcing the MAC addresses. This may seem impossible — but since we know the manufacturer of the WiFi adapter (ESP controller) we can just brute force within the boundaries of their assigned addresses.&lt;/p&gt;
&lt;p&gt;A quick lookup on &lt;a href=&quot;https://macvendors.com/&quot;&gt;https://macvendors.com/&lt;/a&gt; learns that the company is called “ESPRESSIF INC.”. Using that name we can lookup the assigned addresses: &lt;a href=&quot;https://www.adminsub.net/mac-address-finder/espressif&quot;&gt;https://www.adminsub.net/mac-address-finder/espressif&lt;/a&gt;
Giving us the first 3 bytes (as of 10/2016 there are 6x ranges).&lt;/p&gt;
&lt;p&gt;Lets calculate how much MAC addresses we have to test. Keep in mind that ESP is not just used by these light bulbs — so just a fraction is actually used by MagicHue.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A MAC address consists of 6 bytes. Since we have the first 3 bytes we still have
255&lt;em&gt;255&lt;/em&gt;255 possibilities = 16581375
There are 6 different OUI (Organisational Unique Identifier) assigned to ESP. So that means the possibilities are 6 * 1651375 = 99 488 250&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Trying to bind one MAC address takes about 450ms per request (ASP.NET — explains it all). The request will return if the device is online/offline so we do not need to check this.&lt;/p&gt;
&lt;p&gt;This means it would take ~520 days to check all these MAC addresses.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For a hacker, this is fast enough to wait for. Especially when they already have a botnet that can speed up this ‘testing’ action.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;brute-force-proof-of-concept&quot; tabindex=&quot;-1&quot;&gt;Brute force proof of concept&lt;/h2&gt;
&lt;p&gt;A proof of concept Java application that will loop through possible MAC addresses. I chose a range of MAC addresses that I know are sold in Belgium.&lt;/p&gt;
&lt;p&gt;After just a few minutes:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sMNNzBke_UkzJMvAT0zizQ.png&quot; alt=&quot;Devices found after just 2 minutes&quot; /&gt;&lt;/p&gt;
&lt;p&gt;I outputted the list of user email addresses I found for each online device. This proves how “real life” this is.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;You may not know the MAC address of the person you are hacking, but you can basically map each MAC address that you find to a living person. That is what makes this so scary.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The “admin@proofofconcept.fake” is an account I made for this proof of concept.&lt;/p&gt;
&lt;p&gt;This is how the app now looks like after a 2 minute brute force search:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:1002/format:webp/1*sXQwhfrJEVXfcuNkxUzcNg.png&quot; alt=&quot;captionless image&quot; /&gt;&lt;/p&gt;
&lt;h1 id=&quot;how-will-this-be-fixed%3F&quot; tabindex=&quot;-1&quot;&gt;How will this be fixed?&lt;/h1&gt;
&lt;p&gt;They can try to prevent it a bit… but they can’t remotely update the existing devices to make them more secure.&lt;/p&gt;
&lt;p&gt;This basically means that the current line of devices is vulnerable to hacking regardless of whatever the company tries to do — and a hunch tells me this won’t change in the near future.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tips:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Give the devices a unique identifier that is stored on first boot. This ensures that a hacker can’t just guess the MAC address&lt;/li&gt;
&lt;li&gt;Check the timestamps that are send to avoid double requests (slows them down)&lt;/li&gt;
&lt;li&gt;Perform checksums on the requests (slows them down)&lt;/li&gt;
&lt;li&gt;Use TLS — its 2016&lt;/li&gt;
&lt;li&gt;Only allow your IoT devices to be added inside the network they are in&lt;/li&gt;
&lt;li&gt;Possibility of using pin codes for a light can act as a private key (or both)&lt;/li&gt;
&lt;li&gt;Rate limiting the amount of requests&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;what-can-a-hacker-do%3F&quot; tabindex=&quot;-1&quot;&gt;What can a hacker do?&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;They can turn all the lights on and off or just change the colors. We are speaking of millions of sold units&lt;/li&gt;
&lt;li&gt;They can see all emails linked to those light bulbs/rgb controllers&lt;/li&gt;
&lt;li&gt;They can see when you timed your lights to go on or off. Maybe see when a specific user leaves his house or has his house in vacation mode?&lt;/li&gt;
&lt;li&gt;They can further exploit it …&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;conclusion&quot; tabindex=&quot;-1&quot;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Despite having all sorts of ‘security’ measures — I was able to control any light bulb of the company without breaching into the network. Some simple changes like giving each device an unique ID would solve this particular problem ASAP.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;IoT devices come in all shapes and sizes. Some have screens, others are smart under the hood without you even really noticing it.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The problem however is that these IoT devices are made by hardware manufacturers that do not really care about cyber security. A light bulb like this may not be able to inflict a lot of damage apart from energy bills, probable fire hazards and stealth burglary — but from the moment these devices get smarter and smarter they have more possibilities to exploit them.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This proof of concept shows that it isn’t hard to hack all sold devices of an IoT company — what is kind of worrying.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Even if companies fix these “small” security issues it just means we have to search for the next vulnerability in a long list to come…&lt;/p&gt;
</content>
  </entry>
</feed>